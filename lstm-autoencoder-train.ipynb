{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from denoising.autoencoder import *\n",
    "\n",
    "from utils.metrics import get_metrics\n",
    "from data_prep.yahoo_fin_api import load_df\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                  Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 1990-02-26  324.160004  328.670013  323.980011  328.670013  328.670013   \n",
       " 1990-02-27  328.679993  331.940002  328.470001  330.260010  330.260010   \n",
       " 1990-02-28  330.260010  333.480011  330.160004  331.890015  331.890015   \n",
       " 1990-03-01  331.890015  334.399994  331.079987  332.739990  332.739990   \n",
       " 1990-03-02  332.739990  335.540009  332.720001  335.540009  335.540009   \n",
       " \n",
       "                Volume        Mean  \n",
       " Date                               \n",
       " 1990-02-26  148900000  326.370010  \n",
       " 1990-02-27  152590000  329.837502  \n",
       " 1990-02-28  184400000  331.447510  \n",
       " 1990-03-01  157930000  332.527496  \n",
       " 1990-03-02  164330000  334.135002  ,\n",
       " 8313)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_df('data/snp.csv')\n",
    "df.head(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2013-03-25    1554.927490\n",
      "2013-03-26    1557.774963\n",
      "2013-03-27    1560.642487\n",
      "2013-03-28    1565.852478\n",
      "2013-04-01    1565.097504\n",
      "Name: Mean, dtype: float64\n",
      "==========\n",
      "Date\n",
      "2013-04-02    1567.062531\n",
      "2013-04-03    1561.302490\n",
      "2013-04-04    1557.197479\n",
      "2013-04-05    1553.184998\n",
      "2013-04-08    1557.007477\n",
      "Name: Mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "cut_idx = df.iloc[int(len(df) * TRAIN_SIZE)].name\n",
    "data = df['Mean']\n",
    "data_min, data_max = data.min(), data.max()\n",
    "train_data = data[data.index <= cut_idx]\n",
    "test_data = data[cut_idx < data.index]\n",
    "\n",
    "print(train_data.tail())\n",
    "print('=' * 10)\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 326.3700],\n",
       "        [ 329.8375],\n",
       "        [ 331.4475],\n",
       "        ...,\n",
       "        [4024.3076],\n",
       "        [3996.7876],\n",
       "        [4007.1025]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(df['Mean'], dtype=torch.float32).view(-1, 1)\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32).view(-1, 1)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f933c8d3230>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = data.to(device)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Stacked AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "\n",
    "num_epoch = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_encoder = LstmEncoder(HIDDEN_SIZE).to(device)\n",
    "lstm_decoder = LstmDecoder(HIDDEN_SIZE).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(lstm_encoder.parameters()) + list(lstm_decoder.parameters()), lr = 1e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Encoder:\n",
      "LstmEncoder(\n",
      "  (encoder_lstm): LSTM(1, 30, num_layers=5, dropout=0.2, bidirectional=True)\n",
      ")\n",
      "==========================================================================================\n",
      "CNN Decoder:\n",
      "LstmDecoder(\n",
      "  (decoder_lstm): LSTM(1, 30, num_layers=5, dropout=0.2, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('CNN Encoder:')\n",
    "print(lstm_encoder)\n",
    "print('=' * 90)\n",
    "print('CNN Decoder:')\n",
    "print(lstm_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1, got 60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epoch):\n\u001b[1;32m      7\u001b[0m     encoded_data \u001b[39m=\u001b[39m lstm_encoder(data)[\u001b[39m0\u001b[39m] \u001b[39m# Selecting Output only\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     decoded_data \u001b[39m=\u001b[39m lstm_decoder(encoded_data)\n\u001b[1;32m     10\u001b[0m     loss \u001b[39m=\u001b[39m criterion(decoded_data, data)\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/Fin-Data-Denoising/denoising/autoencoder.py:84\u001b[0m, in \u001b[0;36mLstmDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 84\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder_lstm(x)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:772\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    769\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 772\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    774\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    775\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:697\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    693\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    694\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    695\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    696\u001b[0m                        ):\n\u001b[0;32m--> 697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    698\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    699\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[0] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    701\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:210\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    208\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    211\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    212\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1, got 60"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "\n",
    "lstm_encoder.train()\n",
    "lstm_decoder.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    encoded_data = lstm_encoder(data)[0] # Selecting Output only\n",
    "    decoded_data = lstm_decoder(encoded_data)\n",
    "\n",
    "    loss = criterion(decoded_data, data)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    plot_epoch = num_epoch - np.floor(num_epoch * np.log10(np.linspace(1, 10, 20)))\n",
    "    if False and epoch in plot_epoch or epoch == num_epoch - 1:\n",
    "        df['CNNPredMean'] = lstm_decoder(lstm_encoder(data)).detach().cpu().numpy().squeeze()\n",
    "        #df['LSTMPredMean'] = lstm_decoder(lstm_encoder(data)).detach().cpu().numpy().squeeze()\n",
    "        plt.ylim([data_min, data_max])\n",
    "        df[['Mean', 'CNNPredMean']].plot(color=['b', 'r'], figsize=(18, 10))\n",
    "        plt.savefig(f'plots/LSTM-kernel51-epoch{epoch:03}.png')\n",
    "\n",
    "train_loss = pd.Series(train_loss).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_loss.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNNPredMean'] = lstm_decoder(lstm_encoder(data)).detach().cpu().numpy().squeeze()\n",
    "#df['LSTMPredMean'] = lstm_decoder(lstm_encoder(data)).detach().cpu().numpy().squeeze()\n",
    "_ = df[['Mean', 'CNNPredMean']].plot(color=['b', 'r'], figsize=(18, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
